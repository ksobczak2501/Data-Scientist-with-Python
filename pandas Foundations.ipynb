{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of pandas DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import numpy using the standard alias np.\n",
    "Assign the numerical values in the DataFrame df to an array np_vals using the attribute values.\n",
    "Pass np_vals into the NumPy method log10() and store the results in np_vals_log10.\n",
    "Pass the entire df DataFrame into the NumPy method log10() and store the results in df_log10.\n",
    "Inspect the output of the print() code to see the type() of the variables that you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create array of DataFrame values: np_vals\n",
    "np_vals = df.values\n",
    "\n",
    "# Create new array of base 10 logarithm values: np_vals_log10\n",
    "np_vals_log10 = np.log10(np_vals)\n",
    "\n",
    "# Create array of new DataFrame by passing df to np.log10(): df_log10\n",
    "df_log10 = np.log10(df)\n",
    "\n",
    "# Print original and new data containers\n",
    "[print(x, 'has type', type(eval(x))) for x in ['np_vals', 'np_vals_log10', 'df', 'df_log10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building DataFrames from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the 2 lists list_keys and list_values together into one list of (key, value) tuples. Be sure to convert the zip object into a list, and store the result in zipped.\n",
    "Inspect the contents of zipped using print(). This has been done for you.\n",
    "Construct a dictionary using zipped. Store the result as data.\n",
    "Construct a DataFrame using the dictionary. Store the result as df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the 2 lists together into one list of (key,value) tuples: zipped\n",
    "zipped = list(zip(list_keys, list_values))\n",
    "\n",
    "# Inspect the list using print()\n",
    "print(zipped)\n",
    "\n",
    "# Build a dictionary with the zipped list: data\n",
    "data = dict(zipped)\n",
    "\n",
    "# Build and inspect a DataFrame from the dictionary: df\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of new column labels with 'year', 'artist', 'song', 'chart weeks', and assign it to list_labels.\n",
    "Assign your list of labels to df.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of labels: list_labels\n",
    "list_labels = ['year', 'artist', 'song', 'chart weeks']\n",
    "\n",
    "# Assign the list of labels to the columns attribute: df.columns\n",
    "df.columns = list_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a string object with the value 'PA' and assign it to state.\n",
    "Construct a dictionary with 2 key:value pairs: 'state':state and 'city':cities.\n",
    "Construct a pandas DataFrame from the dictionary you created and assign it to df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a string with the value 'PA': state\n",
    "state = 'PA'\n",
    "\n",
    "# Construct a dictionary: data\n",
    "data = {'state':state, 'city':cities}\n",
    "\n",
    "# Construct a DataFrame from dictionary data: df\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & exporting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.read_csv() with the string data_file to read the CSV file into a DataFrame and assign it to df1.\n",
    "Create a list of new column labels - 'year', 'population' - and assign it to the variable new_labels.\n",
    "Reread the same file, again using pd.read_csv(), but this time, add the keyword arguments header=0 and names=new_labels. Assign the resulting DataFrame to df2.\n",
    "Print both the df1 and df2 DataFrames to see the change in column names. This has already been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file: df1\n",
    "df1 = pd.read_csv(data_file)\n",
    "\n",
    "# Create a list of the new column labels: new_labels\n",
    "new_labels = ['year', 'population']\n",
    "\n",
    "# Read in the file, specifying the header and names parameters: df2\n",
    "df2 = pd.read_csv(data_file, header=0, names=new_labels)\n",
    "\n",
    "# Print both the DataFrames\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.read_csv() without using any keyword arguments to read file_messy into a pandas DataFrame df1.\n",
    "Use .head() to print the first 5 rows of df1 and see how messy it is. Do this in the IPython Shell first so you can see how modifying read_csv() can clean up this mess.\n",
    "Using the keyword arguments delimiter=' ', header=3 and comment='#', use pd.read_csv() again to read file_messy into a new DataFrame df2.\n",
    "Print the output of df2.head() to verify the file was read correctly.\n",
    "Use the DataFrame method .to_csv() to save the DataFrame df2 to the variable file_clean. Be sure to specify index=False.\n",
    "Use the DataFrame method .to_excel() to save the DataFrame df2 to the file 'file_clean.xlsx'. Again, remember to specify index=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw file as-is: df1\n",
    "df1 = pd.read_csv(file_messy)\n",
    "\n",
    "# Print the output of df1.head()\n",
    "print(df1.head())\n",
    "\n",
    "# Read in the file with the correct parameters: df2\n",
    "df2 = pd.read_csv(file_messy, delimiter=' ', header=3, comment='#')\n",
    "\n",
    "# Print the output of df2.head()\n",
    "print(df2.head())\n",
    "\n",
    "# Save the cleaned up DataFrame to a CSV file without the index\n",
    "df2.to_csv(file_clean, index=False)\n",
    "\n",
    "# Save the cleaned up DataFrame to an excel file without the index\n",
    "df2.to_excel('file_clean.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the plot with the DataFrame method df.plot(). Specify a color of 'red'.\n",
    "* Use plt.title() to give the plot a title of 'Temperature in Austin'.\n",
    "* Use plt.xlabel() to give the plot an x-axis label of 'Hours since midnight August 1, 2010'.\n",
    "* Use plt.ylabel() to give the plot a y-axis label of 'Temperature (degrees F)'.\n",
    "* Finally, display the plot using plt.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot with color='red'\n",
    "df.plot(color='red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Temperature in Austin')\n",
    "\n",
    "# Specify the x-axis label\n",
    "plt.xlabel('Hours since midnight August 1, 2010')\n",
    "\n",
    "# Specify the y-axis label\n",
    "plt.ylabel('Temperature (degrees F)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all columns together on one figure by calling df.plot(), and noting the vertical scaling problem.\n",
    "Plot all columns as subplots. To do so, you need to specify subplots=True inside .plot().\n",
    "Plot a single column of dew point data. To do this, define a column list containing a single column name 'Dew Point (deg F)', and call df[column_list1].plot().\n",
    "Plot two columns of data, 'Temperature (deg F)' and 'Dew Point (deg F)'. To do this, define a list containing those column names and pass it into df[], as df[column_list2].plot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all columns (default)\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot all columns as subplots\n",
    "df.plot(subplots=True)\n",
    "plt.show()\n",
    "\n",
    "# Plot just the Dew Point data\n",
    "column_list1 = ['Dew Point (deg F)']\n",
    "df[column_list1].plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Dew Point and Temperature data, but not the Pressure data\n",
    "column_list2 = ['Temperature (deg F)','Dew Point (deg F)']\n",
    "df[column_list2].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of y-axis column names called y_columns consisting of 'AAPL' and 'IBM'.\n",
    "Generate a line plot with x='Month' and y=y_columns as inputs.\n",
    "Give the plot a title of 'Monthly stock prices'.\n",
    "Specify the y-axis label.\n",
    "Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of y-axis column names: y_columns\n",
    "y_columns = ['AAPL', 'IBM']\n",
    "\n",
    "# Generate a line plot\n",
    "df.plot(x='Month', y=y_columns)\n",
    "\n",
    "# Add the title\n",
    "plt.title('Monthly stock prices')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Price ($US)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a scatter plot with 'hp' on the x-axis and 'mpg' on the y-axis. Specify s=sizes.\n",
    "Add a title to the plot.\n",
    "Specify the x-axis and y-axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a scatter plot\n",
    "df.plot(kind='scatter', x='hp', y='mpg', s=sizes)\n",
    "\n",
    "# Add the title\n",
    "plt.title('Fuel efficiency vs Horse-power')\n",
    "\n",
    "# Add the x-axis label\n",
    "plt.xlabel('Horse-power')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Fuel efficiency (mpg)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list called cols of the column names to be plotted: 'weight' and 'mpg'.\n",
    "Call plot on df[cols] to generate a box plot of the two columns in a single figure. To do this, specify subplots=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the column names to be plotted: cols\n",
    "cols = ['weight', 'mpg']\n",
    "\n",
    "# Generate the box plots\n",
    "df[cols].plot(kind='box', subplots=True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a PDF for the values in fraction with 30 bins between 0 and 30%. The range has been taken care of for you. ax=axes[0] means that this plot will appear in the first row.\n",
    "Plot a CDF for the values in fraction with 30 bins between 0 and 30%. Again, the range has been specified for you. To make the CDF appear on the second row, you need to specify ax=axes[1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This formats the plots such that they appear on separate rows\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Plot the PDF\n",
    "df.fraction.plot(ax=axes[0], kind='hist', bins=30, normed=True, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "# Plot the CDF\n",
    "df.fraction.plot(ax=axes[1], kind='hist', bins=30, cumulative=True, normed=True, range=(0,.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the minimum value of the 'Engineering' column.\n",
    "Print the maximum value of the 'Engineering' column.\n",
    "Construct the mean percentage per year with .mean(axis='columns'). Assign the result to mean.\n",
    "Plot the average percentage per year. Since 'Year' is the index of df, it will appear on the x-axis of the plot. No keyword arguments are needed in your call to .plot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum value of the Engineering column\n",
    "print(df['Engineering'].min())\n",
    "\n",
    "# Print the maximum value of the Engineering column\n",
    "print(df['Engineering'].max())\n",
    "\n",
    "# Construct the mean percentage per year: mean\n",
    "mean = df.mean(axis='columns')\n",
    "\n",
    "# Plot the average percentage per year\n",
    "mean.plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print summary statistics of the 'fare' column of df with .describe() and print(). Note: df.fare and df['fare'] are equivalent.\n",
    "Generate a box plot of the 'fare' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics of the fare column with .describe()\n",
    "print(df['fare'].describe())\n",
    "\n",
    "# Generate a box plot of the fare column\n",
    "df['fare'].plot(kind='box')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of countries reported in 2015. To do this, use the .count() method on the '2015' column of df.\n",
    "Print the 5th and 95th percentiles of df. To do this, use the .quantile() method with the list [0.05, 0.95].\n",
    "Generate a box plot using the list of columns provided in years. This has already been done for you, so click on 'Submit Answer' to view the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of countries reported in 2015\n",
    "print(df['2015'].count())\n",
    "\n",
    "# Print the 5th and 95th percentiles\n",
    "print(df.quantile([0.05,0.95]))\n",
    "\n",
    "# Generate a box plot\n",
    "years = ['1800','1850','1900','1950','2000']\n",
    "df[years].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and print the means of the January and March data using the .mean() method.\n",
    "Compute and print the standard deviations of the January and March data using the .std() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean of the January and March data\n",
    "print(january.mean(), march.mean())\n",
    "\n",
    "# Print the standard deviation of the January and March data\n",
    "print(january.std(), march.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating populations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the global mean and global standard deviations of df using the .mean() and .std() methods. Assign the results to global_mean and global_std.\n",
    "Filter the 'US' population from the 'origin' column and assign the result to us.\n",
    "Compute the US mean and US standard deviations of us using the .mean() and .std() methods. Assign the results to us_mean and us_std.\n",
    "Print the differences between us_mean and global_mean and us_std and global_std. This has already been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global mean and global standard deviation: global_mean, global_std\n",
    "global_mean = df.mean()\n",
    "global_std = df.std()\n",
    "\n",
    "# Filter the US population from the origin column: us\n",
    "us = df[df['origin'] == 'US']\n",
    "\n",
    "# Compute the US mean and US standard deviation: us_mean, us_std\n",
    "us_mean = us.mean()\n",
    "us_std = us.std()\n",
    "\n",
    "# Print the differences\n",
    "print(us_mean - global_mean)\n",
    "print(us_std - global_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside plt.subplots(), specify the nrows and ncols parameters so that there are 3 rows and 1 column.\n",
    "Filter the rows where the 'pclass' column has the values 1 and generate a box plot of the 'fare' column.\n",
    "Filter the rows where the 'pclass' column has the values 2 and generate a box plot of the 'fare' column.\n",
    "Filter the rows where the 'pclass' column has the values 3 and generate a box plot of the 'fare' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the box plots on 3 separate rows and 1 column\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Generate a box plot of the fare prices for the First passenger class\n",
    "titanic.loc[titanic['pclass'] == 1].plot(ax=axes[0], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Second passenger class\n",
    "titanic.loc[titanic['pclass'] == 2].plot(ax=axes[1], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Third passenger class\n",
    "titanic.loc[titanic['pclass'] == 3].plot(ax=axes[2], y='fare', kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a format string, time_format, using '%Y-%m-%d %H:%M' as the desired format.\n",
    "Convert date_list into a datetime object by using the pd.to_datetime() function. Specify the format string you defined above and assign the result to my_datetimes.\n",
    "Construct a pandas Series called time_series using pd.Series() with temperature_list and my_datetimes. Set the index of the Series to be my_datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a format string: time_format\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "\n",
    "# Convert date_list into a datetime object: my_datetimes\n",
    "my_datetimes = pd.to_datetime(date_list, format = time_format)  \n",
    "\n",
    "# Construct a pandas Series using temperature_list and my_datetimes: time_series\n",
    "time_series = pd.Series(temperature_list, index=my_datetimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from ts0 for a single hour - the hour from 9pm to 10pm on 2010-10-11. Assign it to ts1.\n",
    "Extract data from ts0 for a single day - July 4th, 2010 - and assign it to ts2.\n",
    "Extract data from ts0 for the second half of December 2010 - 12/15/2010 to 12/31/2010. Assign it to ts3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour from 9pm to 10pm on '2010-10-11': ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']\n",
    "\n",
    "# Extract '2010-07-04' from ts0: ts2\n",
    "ts2 = ts0.loc['2010-07-04']\n",
    "\n",
    "# Extract data from '2010-12-15' to '2010-12-31': ts3\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new time series ts3 by reindexing ts2 with the index of ts1. To do this, call .reindex() on ts2 and pass in the index of ts1 (ts1.index).\n",
    "Create another new time series, ts4, by calling the same .reindex() as above, but also specifiying a fill method, using the keyword argument method=\"ffill\" to forward-fill values.\n",
    "Add ts1 + ts2. Assign the result to sum12.\n",
    "Add ts1 + ts3. Assign the result to sum13.\n",
    "Add ts1 + ts4, Assign the result to sum14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex without fill method: ts3\n",
    "ts3 = ts2.reindex(ts1.index)\n",
    "\n",
    "# Reindex with fill method, using forward fill: ts4\n",
    "ts4 = ts2.reindex(ts1.index, method='ffill')\n",
    "\n",
    "# Combine ts1 + ts2: sum12\n",
    "sum12 = ts1+ts2\n",
    "\n",
    "# Combine ts1 + ts3: sum13\n",
    "sum13 = ts1+ts3\n",
    "\n",
    "# Combine ts1 + ts4: sum14\n",
    "sum14 = ts1+ts4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling time series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample the 'Temperature' column of df to 6 hour data using .resample('6h') and .mean(). Assign the result to df1.\n",
    "Downsample the 'Temperature' column of df to daily data using .resample('D') and then count the number of data points in each day with .count(). Assign the result df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample to 6 hour data and aggregate by mean: df1\n",
    "df1 = df['Temperature'].resample('6h').mean()\n",
    "\n",
    "# Downsample to daily data and count the number of data points: df2\n",
    "df2 = df['Temperature'].resample('D').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use partial string indexing to extract temperature data for August 2010 into august.\n",
    "Use the temperature data for August and downsample to find the daily maximum temperatures. Store the result in august_highs.\n",
    "Use partial string indexing to extract temperature data for February 2010 into february.\n",
    "Use the temperature data for February and downsample to find the daily minimum temperatures. Store the result in february_lows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temperature data for August: august\n",
    "august = df.loc['2010-August','Temperature']\n",
    "\n",
    "# Downsample to obtain only the daily highest temperatures in August: august_highs\n",
    "august_highs = august.resample('D').max()\n",
    "\n",
    "# Extract temperature data for February: february\n",
    "february = df.loc['2010-February','Temperature']\n",
    "\n",
    "# Downsample to obtain the daily lowest temperatures in February: february_lows\n",
    "february_lows = february.resample('D').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use partial string indexing to extract temperature data from August 1 2010 to August 15 2010. Assign to unsmoothed.\n",
    "Use .rolling() with a 24 hour window to smooth the mean temperature data. Assign the result to smoothed.\n",
    "Use a dictionary to create a new DataFrame august with the time series smoothed and unsmoothed as columns.\n",
    "Plot both the columns of august as line plots using the .plot() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed\n",
    "unsmoothed = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
    "\n",
    "# Apply a rolling mean with a 24 hour window: smoothed\n",
    "smoothed = unsmoothed.rolling(window=24).mean()\n",
    "\n",
    "# Create a new DataFrame with columns smoothed and unsmoothed: august\n",
    "august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})\n",
    "\n",
    "# Plot both smoothed and unsmoothed data using august.plot().\n",
    "august.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use partial string indexing to extract August 2010 temperature data, and assign to august.\n",
    "Resample to daily frequency, saving the maximum daily temperatures, and assign the result to daily_highs.\n",
    "As part of one long method chain, repeat the above resampling (or you can re-use daily_highs) and then combine it with .rolling() to apply a 7 day .mean() (with window=7 inside .rolling()) so as to smooth the daily highs. Assign the result to daily_highs_smoothed and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the August 2010 data: august\n",
    "august = df['Temperature']['2010-August']\n",
    "\n",
    "# Resample to daily data, aggregating by max: daily_highs\n",
    "daily_highs = august.resample('D').max()\n",
    "\n",
    "# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August\n",
    "daily_highs_smoothed = daily_highs.rolling(window=7).mean()\n",
    "print(daily_highs_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating time series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .str.strip() to strip extra whitespace from df.columns. Assign the result back to df.columns.\n",
    "In the 'Destination Airport' column, extract all entries where Dallas ('DAL') is the destination airport. Use .str.contains('DAL') for this and store the result in dallas.\n",
    "Resample dallas such that you get the total number of departures each day. Store the result in daily_departures.\n",
    "Generate summary statistics for daily Dallas departures using .describe(). Store the result in stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip extra whitespace from the column names: df.columns\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Extract data for which the destination airport is Dallas: dallas\n",
    "dallas = df['Destination Airport'].str.contains('DAL')\n",
    "\n",
    "# Compute the total number of Dallas departures each day: daily_departures\n",
    "daily_departures = dallas.resample('D').sum()\n",
    "\n",
    "# Generate the summary statistics for daily Dallas departures: stats\n",
    "stats = daily_departures.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the index of ts2 with that of ts1, and then fill in the missing values of ts2 by using .interpolate(how='linear'). Save the result as ts2_interp.\n",
    "Compute the difference between ts1 and ts2_interp. Take the absolute value of the difference with np.abs(), and assign the result to differences.\n",
    "Generate and print summary statistics of the differences with .describe() and print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp\n",
    "ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear')\n",
    "\n",
    "# Compute the absolute difference of ts1 and ts2_interp: differences \n",
    "differences = np.abs(ts1-ts2_interp)\n",
    "\n",
    "# Generate and print summary statistics of the differences\n",
    "print(differences.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Boolean mask, mask, such that if the 'Destination Airport' column of df equals 'LAX', the result is True, and otherwise, it is False.\n",
    "Use the mask to filter for only the LAX rows. Assign the result to la.\n",
    "Concatenate the two columns la['Date (MM/DD/YYYY)'] and la['Wheels-off Time'] with a ' ' space in between. Pass this to pd.to_datetime() to create a datetime array of all the times the LAX-bound flights left the ground.\n",
    "Use Series.dt.tz_localize() to localize the time to 'US/Central'.\n",
    "Use the .dt.tz_convert() method to convert datetimes from 'US/Central' to 'US/Pacific'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Boolean mask to filter for the 'LAX' departure flights: mask\n",
    "mask = df['Destination Airport'] == 'LAX'\n",
    "\n",
    "# Use the mask to subset the data: la\n",
    "la = df[mask]\n",
    "\n",
    "# Combine two columns of data to create a datetime series: times_tz_none \n",
    "times_tz_none = pd.to_datetime( la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'] )\n",
    "\n",
    "# Localize the time to US/Central: times_tz_central\n",
    "times_tz_central = times_tz_none.dt.tz_localize('US/Central')\n",
    "\n",
    "# Convert the datetimes from US/Central to US/Pacific\n",
    "times_tz_pacific = times_tz_central.dt.tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.to_datetime() to convert the 'Date' column in df to a collection of datetime objects, and assign back to df.Date.\n",
    "Set the index to this updated 'Date' column, using df.set_index() with the optional keyword argument inplace=True, so that you don't have to assign the result back to df.\n",
    "Re-plot the DataFrame to see that the axis is now datetime aware. This code has been written for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data before setting the datetime index\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Convert the 'Date' column into a collection of datetime objects: df.Date\n",
    "df.Date = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the index to be the converted 'Date' column\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Re-plot the DataFrame to see that the axis is now datetime aware!\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the summer temperatures using method chaining. The summer ranges from the months '2010-Jun' to '2010-Aug'.\n",
    "Plot the temperatures for one week in June using the same method chaining, but this time indexing with '2010-06-10':'2010-06-17' before you follow up with .plot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the summer data\n",
    "df.Temperature['2010-Jun':'2010-Aug'].plot()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Plot the one week data\n",
    "df.Temperature['2010-06-10':'2010-06-17'].plot()\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas as pd.\n",
    "Read the file data_file into a DataFrame called df.\n",
    "Print the output of df.head(). This has been done for you. Notice the formatting problems in df.\n",
    "Re-read the data using specifying the keyword argument header=None and assign it to df_headers.\n",
    "Print the output of df_headers.head(). This has already been done for you. Hit 'Submit Answer' and see how this resolves the formatting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the data file: df\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Print the output of df.head()\n",
    "print(df.head())\n",
    "\n",
    "# Read in the data file with header=None: df_headers\n",
    "df_headers = pd.read_csv(data_file, header=None)\n",
    "\n",
    "# Print the output of df_headers.head()\n",
    "print(df_headers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the comma separated string column_labels to a list of strings using .split(','). Assign the result to column_labels_list.\n",
    "Reassign df.columns using the list of strings column_labels_list.\n",
    "Call df.drop() with list_to_drop and axis='columns'. Assign the result to df_dropped.\n",
    "Print df_dropped.head() to examine the result. This has already been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split on the comma to create a list: column_labels_list\n",
    "column_labels_list = list(column_labels.split(','))\n",
    "\n",
    "# Assign the new column labels to the DataFrame: df.columns\n",
    "df.columns = column_labels_list\n",
    "\n",
    "# Remove the appropriate columns: df_dropped\n",
    "df_dropped = df.drop(list_to_drop, axis='columns')\n",
    "\n",
    "# Print the output of df_dropped.head()\n",
    "print(df_dropped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the 'date' column to a string with .astype(str) and assign to df_dropped['date'].\n",
    "Add leading zeros to the 'Time' column. This has been done for you.\n",
    "Concatenate the new 'date' and 'Time' columns together. Assign to date_string.\n",
    "Convert the date_string Series to datetime values with pd.to_datetime(). Specify the format parameter.\n",
    "Set the index of the df_dropped DataFrame to be date_times. Assign the result to df_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to string: df_dropped['date']\n",
    "df_dropped['date'] = df_dropped['date'].astype(str)\n",
    "\n",
    "# Pad leading zeros to the Time column: df_dropped['Time']\n",
    "df_dropped['Time'] = df_dropped['Time'].apply(lambda x:'{:0>4}'.format(x))\n",
    "\n",
    "# Concatenate the new date and Time columns: date_string\n",
    "date_string = df_dropped['date']+df_dropped['Time']\n",
    "\n",
    "# Convert the date_string Series to datetime: date_times\n",
    "date_times = pd.to_datetime(date_string, format='%Y%m%d%H%M')\n",
    "\n",
    "# Set the index to be the new date_times container: df_clean\n",
    "df_clean = df_dropped.set_index(date_times)\n",
    "\n",
    "# Print the output of df_clean.head()\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 'dry_bulb_faren' temperature between 8 AM and 9 AM on June 20, 2011.\n",
    "Convert the 'dry_bulb_faren' column to numeric values with pd.to_numeric(). Specify errors='coerce'.\n",
    "Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011.\n",
    "Convert the 'wind_speed' and 'dew_point_faren' columns to numeric values with pd.to_numeric(). Again, specify errors='coerce'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-Jun-20 8:00':'2011-Jun-20 9:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the dry_bulb_faren column to numeric values: df_clean['dry_bulb_faren']\n",
    "df_clean['dry_bulb_faren'] = pd.to_numeric(df_clean['dry_bulb_faren'], errors='coerce')\n",
    "\n",
    "# Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\n",
    "print(df_clean.loc['2011-Jun-20 8:00':'2011-Jun-20 9:00', 'dry_bulb_faren'])\n",
    "\n",
    "# Convert the wind_speed and dew_point_faren columns to numeric values\n",
    "df_clean['wind_speed'] = pd.to_numeric(df_clean['wind_speed'], errors='coerce')\n",
    "df_clean['dew_point_faren'] = pd.to_numeric(df_clean['dew_point_faren'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 'dry_bulb_faren' column and print the output of .median().\n",
    "Use .loc[] to select the range '2011-Apr':'2011-Jun' from dry_bulb_faren' and print the output of .median().\n",
    "Use .loc[] to select the month '2011-Jan' from 'dry_bulb_faren' and print the output of .median()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the median of the dry_bulb_faren column\n",
    "print(df_clean['dry_bulb_faren'].median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the time range '2011-Apr':'2011-Jun'\n",
    "print(df_clean.loc['2011-Apr':'2011-Jun', 'dry_bulb_faren'].median())\n",
    "\n",
    "# Print the median of the dry_bulb_faren column for the month of January\n",
    "print(df_clean.loc['2011-Jan', 'dry_bulb_faren'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample df_clean with daily frequency and aggregate by the mean. Store the result as daily_mean_2011.\n",
    "Extract the 'dry_bulb_faren' column from daily_mean_2011 as a NumPy array using .values. Store the result as daily_temp_2011. Note: .values is an attribute, not a method, so you don't have to use ().\n",
    "Downsample df_climate with daily frequency and aggregate by the mean. Store the result as daily_climate.\n",
    "Reset the index of daily_climate and extract the Temperature column. To do this, first reset the index of daily_climate using the .reset_index() method, and then use bracket slicing to access 'Temperature'. Store the result as daily_temp_climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample df_clean by day and aggregate by mean: daily_mean_2011\n",
    "daily_mean_2011 = df_clean.resample('D').mean()\n",
    "\n",
    "# Extract the dry_bulb_faren column from daily_mean_2011 using .values: daily_temp_2011\n",
    "daily_temp_2011 = daily_mean_2011['dry_bulb_faren'].values\n",
    "\n",
    "# Downsample df_climate by day and aggregate by mean: daily_climate\n",
    "daily_climate = df_climate.resample('D').mean()\n",
    "\n",
    "# Extract the Temperature column from daily_climate using .reset_index(): daily_temp_climate\n",
    "daily_temp_climate = daily_climate.reset_index()['Temperature']\n",
    "\n",
    "# Compute the difference between the two arrays and print the mean difference\n",
    "difference = daily_temp_2011 - daily_temp_climate\n",
    "print(difference.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cases in df_clean where the sky is clear. That is, when 'sky_condition' equals 'CLR', assigning to is_sky_clear.\n",
    "Use .loc[] to filter df_clean by is_sky_clear, assigning to sunny.\n",
    "Resample sunny by day ('D'), and take the max to find the maximum daily temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df_clean, when is sky_condition 'CLR'?\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "\n",
    "# Filter df_clean using is_sky_clear\n",
    "sunny = df_clean.loc[is_sky_clear]\n",
    "\n",
    "# Resample sunny by day then calculate the max\n",
    "sunny_daily_max = sunny.resample('D').max()\n",
    "\n",
    "# See the result\n",
    "sunny_daily_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cases in df_clean where the sky is overcast. Using .str.contains(), find when 'sky_condition' contains 'OVC', assigning to is_sky_overcast.\n",
    "Use .loc[] to filter df_clean by is_sky_overcast, assigning to overcast.\n",
    "Resample overcast by day ('D'), and take the max to find the maximum daily temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df_clean, when does sky_condition contain 'OVC'?\n",
    "is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')\n",
    "\n",
    "# Filter df_clean using is_sky_overcast\n",
    "overcast = df_clean.loc[is_sky_overcast]\n",
    "\n",
    "# Resample overcast by day then calculate the max\n",
    "overcast_daily_max = overcast.resample('D').max()\n",
    "\n",
    "# See the result\n",
    "overcast_daily_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of sunny_daily_max, assigning to sunny_daily_max_mean.\n",
    "Calculate the mean of overcast_daily_max, assigning to overcast_daily_max_mean.\n",
    "Print sunny_daily_max_mean minus overcast_daily_max_mean. How much hotter are sunny days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "sunny = df_clean.loc[is_sky_clear]\n",
    "sunny_daily_max = sunny.resample('D').max()\n",
    "is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')\n",
    "overcast = df_clean.loc[is_sky_overcast]\n",
    "overcast_daily_max = overcast.resample('D').max()\n",
    "\n",
    "# Calculate the mean of sunny_daily_max\n",
    "sunny_daily_max_mean = sunny_daily_max.mean()\n",
    "\n",
    "# Calculate the mean of overcast_daily_max\n",
    "overcast_daily_max_mean = overcast_daily_max.mean()\n",
    "\n",
    "# Print the difference (sunny minus overcast)\n",
    "print(sunny_daily_max_mean-overcast_daily_max_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib.pyplot as plt.\n",
    "Select the 'visibility' and 'dry_bulb_faren' columns and resample them by week, aggregating the mean. Assign the result to weekly_mean.\n",
    "Print the output of weekly_mean.corr().\n",
    "Plot the weekly_mean dataframe with .plot(), specifying subplots=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the visibility and dry_bulb_faren columns and resample them: weekly_mean\n",
    "weekly_mean = df_clean[['visibility','dry_bulb_faren']].resample('W').mean()\n",
    "\n",
    "# Print the output of weekly_mean.corr()\n",
    "print(weekly_mean.corr())\n",
    "\n",
    "# Plot weekly_mean with subplots=True\n",
    "weekly_mean.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cases in df_clean where the sky is clear. That is, when 'sky_condition' equals 'CLR', assigning the result to is_sky_clear.\n",
    "Resample is_sky_clear by day, assigning to resampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df_clean, when is sky_condition 'CLR'?\n",
    "is_sky_clear = df_clean[df_clean['sky_condition']=='CLR']\n",
    "\n",
    "# Resample is_sky_clear by day\n",
    "resampled = is_sky_clear.resample('D')\n",
    "\n",
    "# See the result\n",
    "resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cases in df_clean where the sky is clear. That is, when 'sky_condition' equals 'CLR', assigning the result to is_sky_clear.\n",
    "Resample is_sky_clear by day, assigning to resampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using df_clean, when is sky_condition 'CLR'?\n",
    "is_sky_clear = df_clean['sky_condition']=='CLR'\n",
    "\n",
    "# Resample is_sky_clear by day\n",
    "resampled = is_sky_clear.resample('D').sum()\n",
    "\n",
    "# See the result\n",
    "resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of measured sunny hours per day as the sum of resampled, assigning to sunny_hours.\n",
    "Calculate the total number of measured hours per day as the count of resampled, assigning to total_hours.\n",
    "Calculate the fraction of hours per day that were sunny as the ratio of sunny hours to total hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "resampled = is_sky_clear.resample('D')\n",
    "\n",
    "# Calculate the number of sunny hours per day\n",
    "sunny_hours = resampled.sum()\n",
    "\n",
    "# Calculate the number of measured hours per day\n",
    "total_hours = resampled.count()\n",
    "\n",
    "# Calculate the fraction of hours per day that were sunny\n",
    "sunny_fraction = sunny_hours/total_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a box plot of sunny_fraction using .plot() with kind set to 'box'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous steps\n",
    "is_sky_clear = df_clean['sky_condition'] == 'CLR'\n",
    "resampled = is_sky_clear.resample('D')\n",
    "sunny_hours = resampled.sum()\n",
    "total_hours = resampled.count()\n",
    "sunny_fraction = sunny_hours / total_hours\n",
    "\n",
    "# Make a box plot of sunny_fraction\n",
    "sunny_fraction.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 'dew_point_faren' and 'dry_bulb_faren' columns (in that order). Resample by month and aggregate the maximum monthly temperatures. Assign the result to monthly_max.\n",
    "Plot a histogram of the resampled data with bins=8, alpha=0.5, and subplots=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample dew_point_faren and dry_bulb_faren by Month, aggregating the maximum values: monthly_max\n",
    "monthly_max = df_clean[['dew_point_faren','dry_bulb_faren']].resample('M').max()\n",
    "\n",
    "# Generate a histogram with bins=8, alpha=0.5, subplots=True\n",
    "monthly_max.plot(kind='hist',bins=8,alpha=0.5,subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From df_climate, extract the maximum temperature observed in August 2010. The relevant column here is 'Temperature'. You can select the rows corresponding to August 2010 in multiple ways. For example, df_climate.loc['2011-Feb'] selects all rows corresponding to February 2011, while df_climate.loc['2009-09', 'Pressure'] selects the rows corresponding to September 2009 from the 'Pressure' column.\n",
    "From df_clean, select the August 2011 temperature data from the 'dry_bulb_faren'. Resample this data by day and aggregate the maximum value. Store the result in august_2011.\n",
    "Filter rows of august_2011 to keep days where the value exceeded august_max. Store the result in august_2011_high.\n",
    "Construct a CDF of august_2011_high using 25 bins. Remember to specify the kind, normed, and cumulative parameters in addition to bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the maximum temperature in August 2010 from df_climate: august_max\n",
    "august_max = df_climate.loc['2010-Aug','Temperature'].max()\n",
    "print(august_max)\n",
    "\n",
    "# Resample August 2011 temps in df_clean by day & aggregate the max value: august_2011\n",
    "august_2011 = df_clean.loc['2011-Aug','dry_bulb_faren'].resample('D').max()\n",
    "\n",
    "# Filter for days in august_2011 where the value exceeds august_max: august_2011_high\n",
    "august_2011_high = august_2011.loc[august_2011>august_max]\n",
    "\n",
    "# Construct a CDF of august_2011_high\n",
    "august_2011_high.plot(kind='hist', normed=True, cumulative=True, bins=25)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
